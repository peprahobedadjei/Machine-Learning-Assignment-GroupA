{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display library versions\n",
    "print(\"Library Versions:\")\n",
    "print(f\"OS: {os.name}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "\n",
    "# Check if TensorFlow is using GPU or CPU\n",
    "print(\"\\nTensorFlow Device Status:\")\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"TensorFlow is using GPU.\")\n",
    "    print(f\"Available GPU devices: {tf.config.list_physical_devices('GPU')}\")\n",
    "else:\n",
    "    print(\"TensorFlow is using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Variables \n",
    "MIN_IMGS_IN_CLASS=500;\n",
    "image_size = 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the meta files on the 43 seperate traffic sign classes we are learning to identify \n",
    "plt.figure(figsize=(18, 18))\n",
    "for i in range (0,43):\n",
    "    plt.subplot(8,8,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    path = \"data/meta/{0}.png\".format(i)\n",
    "    img = plt.imread(path)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_data = pd.read_csv('data/train.csv')\n",
    "train_image_data.describe\n",
    "train_image_data.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_data.boxplot(['Width', 'Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_data.value_counts('ClassId').plot(\n",
    "    kind='pie',\n",
    "    figsize=(10, 10),\n",
    "    autopct='%1.1f%%',  # Display percentages\n",
    "    startangle=90,      # Start the pie chart at 90 degrees\n",
    "    title='Percentage of Images in Each Category'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create bar chart with horizontal orientation\n",
    "ax = train_image_data.value_counts('ClassId').plot(\n",
    "    kind='barh',                     # Horizontal bar chart\n",
    "    figsize=(20, 10),                # Customize figure size\n",
    "    color='lightgreen',              # Bar color\n",
    "    edgecolor='black',               # Outline for bars\n",
    "    title='Number of Labelled Images in Each Category'  # Title\n",
    ")\n",
    "\n",
    "# Annotate the bars with their values\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(int(p.get_width())), (p.get_width() + 5, p.get_y() + 0.5),\n",
    "                ha='left', va='center', fontsize=10, color='black', xytext=(0, 0),\n",
    "                textcoords='offset points')\n",
    "\n",
    "# Add axis labels\n",
    "plt.xlabel('Count of Images')\n",
    "plt.ylabel('Class ID')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to perform tasks \n",
    "#Preprocess function\n",
    "def preprocess(image, out_side):\n",
    "    height, width = image.shape[:2]\n",
    "    scale = out_side / max(height, width)\n",
    "    dx = (out_side - scale * width) / 2\n",
    "    dy = (out_side - scale * height) / 2\n",
    "    trans = np.array([[scale, 0, dx], [0, scale, dy]], dtype=np.float32)\n",
    "    image = cv2.warpAffine(image, trans, (out_side, out_side), flags=cv2.INTER_AREA)\n",
    "    image = cv2.resize(image, (out_side, out_side))\n",
    "    return image\n",
    "\n",
    "#mixing images function\n",
    "def mixing(images, labels):\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    s = np.arange(images.shape[0])\n",
    "    np.random.seed(43)\n",
    "    np.random.shuffle(s)\n",
    "    images=images[s]\n",
    "    labels=labels[s]\n",
    "    return images, labels\n",
    "\n",
    "#load train images function\n",
    "def load_train(path, out_side):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(os.path.join(path, 'train')):\n",
    "        \n",
    "        cur_path = os.path.join(path, 'train', folder)\n",
    "        print(cur_path)\n",
    "        for file_name in os.listdir(cur_path):\n",
    "            image = cv2.imread(os.path.join(cur_path, file_name))\n",
    "            images.append(preprocess(image, out_side))\n",
    "            labels.append(int(folder))\n",
    "\n",
    "    return mixing(images, labels)\n",
    "\n",
    "#load test images function\n",
    "def load_test(path, out_side):\n",
    "    images = []\n",
    "    labels = []\n",
    "    with open(os.path.join(path, 'test.csv'), 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for rows in reader:\n",
    "            name = rows[7]\n",
    "            if (name == 'Path'):\n",
    "                continue\n",
    "            image = cv2.imread(os.path.join(path, rows[7]))\n",
    "            images.append(preprocess(image, out_side))\n",
    "            labels.append(int(rows[6]))\n",
    "\n",
    "    return mixing(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train images\n",
    "train_images, train_labels = load_train(\"data/\", image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we have the training data loaded, we can preview them\n",
    "def preview(images, labels):\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for c in range(len(np.unique(labels))):\n",
    "        i = random.choice(np.where(labels == c)[0])\n",
    "        plt.subplot(8, 8, c+1)\n",
    "        plt.axis('off')\n",
    "        plt.title('class: {}'.format(c))\n",
    "        plt.imshow(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augumentation\n",
    "def augment_imgs(imgs, p):\n",
    "    \"\"\"\n",
    "    Performs a set of augmentations with with a probability p\n",
    "    \"\"\"\n",
    "    from imgaug import augmenters as iaa\n",
    "    augs =  iaa.SomeOf((2, 4),\n",
    "          [\n",
    "              iaa.Crop(px=(0, 4)), # crop images from each side by 0 to 4px (randomly chosen)\n",
    "              iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}),\n",
    "              iaa.Affine(translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}),\n",
    "              iaa.Affine(rotate=(-45, 45)), # rotate by -45 to +45 degrees)\n",
    "              iaa.Affine(shear=(-10, 10)) # shear by -10 to +10 degrees\n",
    "          ])\n",
    "    \n",
    "    seq = iaa.Sequential([iaa.Sometimes(p, augs)])\n",
    "    res = seq.augment_images(imgs)\n",
    "    return res\n",
    "\n",
    "def count_images_in_classes(lbls):\n",
    "    dct = {}\n",
    "    for i in lbls:\n",
    "        if i in dct:\n",
    "            dct[i] += 1\n",
    "        else:\n",
    "            dct[i] = 1\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(imgs, lbls):\n",
    "    classes = train_image_data.value_counts('ClassId').to_dict()\n",
    "    for i in range(len(classes)):\n",
    "        if (classes[i] < MIN_IMGS_IN_CLASS):\n",
    "            # Number of samples to be added\n",
    "            add_num = MIN_IMGS_IN_CLASS - classes[i]\n",
    "            imgs_for_augm = []\n",
    "            lbls_for_augm = []\n",
    "            for j in range(add_num):\n",
    "                im_index = random.choice(np.where(lbls == i)[0])\n",
    "                imgs_for_augm.append(imgs[im_index])\n",
    "                lbls_for_augm.append(lbls[im_index])\n",
    "            augmented_class = augment_imgs(imgs_for_augm, 1)\n",
    "            augmented_class_np = np.array(augmented_class)\n",
    "            augmented_lbls_np = np.array(lbls_for_augm)\n",
    "            imgs = np.concatenate((imgs, augmented_class_np), axis=0)\n",
    "            lbls = np.concatenate((lbls, augmented_lbls_np), axis=0)\n",
    "    return (imgs, lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = augmentation(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.Series(count_images_in_classes(train_labels))\n",
    "labels = labels.sort_values(ascending=False)\n",
    "labels.plot(kind='barh',figsize=(20, 10), ylabel='CountClassId', title='Number of labelled images in each category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create bar chart\n",
    "ax = labels.plot(\n",
    "    kind='bar',\n",
    "    figsize=(20, 10),\n",
    "    color='lightgreen',\n",
    "    edgecolor='black',\n",
    "    title='Number of Images in Each Category'\n",
    ")\n",
    "\n",
    "# Annotate the bars with their values\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='baseline', fontsize=10, color='black', xytext=(0, 5),\n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Count of Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "train_images = train_images.astype('float32') / 255.\n",
    "# train_images_test = rgb2gray(train_images)\n",
    "\n",
    "train_labels_cat = utils.to_categorical(train_labels, 43)\n",
    "\n",
    "preview(train_images, train_labels)\n",
    "print('Loading: ', time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 43\n",
    "batch = 128\n",
    "epochs = 2\n",
    "learning_rate = 0.0001\n",
    "\n",
    "def results(model):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start = time()\n",
    "    history = model.fit(train_images, train_labels_cat, batch_size=batch, epochs=epochs, validation_split=0.2, shuffle = True, verbose=1)\n",
    "    train_time = time() - start\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label = 'train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(history.history['loss'], label = 'train_loss')\n",
    "    plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "results(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Model\n",
    "test_image_data = pd.read_csv('data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = load_test(\"data/\", image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.astype('float32') / 255.\n",
    "test_labels = utils.to_categorical(test_labels, 43)\n",
    "print('Loading: ', time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_time = time() - start\n",
    "\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test time: ', test_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
